Below is a sample Markdown guide for integrating and using **ai-pydantic** within an AI assistant project. This assumes you have access to Python, a recent `pip` environment, and familiarity with integrating AI models via Python libraries.

---

# Using `ai-pydantic` in Your AI Assistant

## Overview

[`ai-pydantic`](https://ai.pydantic.dev/) provides a structured way to interact with Large Language Models (LLMs) by defining typed schemas using [Pydantic](https://docs.pydantic.dev/) models. This ensures that responses generated by LLMs are reliable and adhere to clearly defined data structures. For AI assistants that rely on prompt chaining, data extraction, or complex reasoning steps, `ai-pydantic` adds a strong validation layer, reducing the need to manually parse model outputs.

## Key Features

- **Pydantic Models for AI**: Define input and output schemas as Pydantic models.
- **Validation & Type Enforcement**: Automatically validate AI responses against the defined schema.
- **Simple Integration**: Works with OpenAI’s GPT endpoints and other LLM APIs that provide text completion or chat completion.
- **Prompt Customization**: Easily provide context, examples, and constraints directly via model fields.

## Installation

```bash
pip install ai-pydantic
```

Ensure you have a recent version of Python (3.9+) and `pydantic`.

## Basic Usage

1. **Define Your Model**: Create a Pydantic model describing the structure you expect from the AI’s response.

   ```python
   from pydantic import BaseModel
   from typing import List

   class MovieRecommendation(BaseModel):
       title: str
       genres: List[str]
       rating: float
       description: str
   ```

2. **Integrate `ai-pydantic`**: Use the `Completion` or `ChatCompletion` classes from `ai-pydantic` to prompt your model.

   ```python
   from ai_pydantic import Completion

   # Provide your OpenAI API key in environment variables or configuration
   completion = Completion[MovieRecommendation](
       openai_api_key="YOUR_OPENAI_API_KEY", 
       prompt_template="Recommend a movie with a title, a list of genres, a rating, and a brief description."
   )
   ```

3. **Generate and Validate**: When you run the completion, the response will be validated against the `MovieRecommendation` schema.

   ```python
   response = completion()
   print(response)
   # MovieRecommendation(title="Inception", genres=["Sci-Fi", "Thriller"], rating=8.8, description="A thief with the ability to enter people's dreams and steal their secrets...")
   ```

   If the AI’s response doesn’t match the schema (e.g., missing fields or invalid data types), `ai-pydantic` will raise a validation error, prompting you to handle the exception.

## Using Chat Models

For chat-based models (like GPT-4), use `ChatCompletion`:

```python
from ai_pydantic import ChatCompletion, Message

completion = ChatCompletion[MovieRecommendation](
    openai_api_key="YOUR_OPENAI_API_KEY",
    messages=[
        Message(role="system", content="You are a helpful assistant."),
        Message(role="user", content="Recommend a good science fiction movie.")
    ]
)

response = completion()
print(response)
```

## Prompt Customization

You can include example responses, constraints, and more details in your prompt to guide the LLM’s output. For instance:

```python
completion = Completion[MovieRecommendation](
    openai_api_key="YOUR_OPENAI_API_KEY",
    prompt_template="""
    I want you to recommend a movie:
    - Include one movie title
    - Include a short list of genres
    - Provide an IMDb rating as a floating number
    - Describe the movie in one or two sentences

    Respond only with JSON that matches the specified schema.
    """
)
```

## Error Handling

If the response is invalid, handle it gracefully:

```python
try:
    response = completion()
    print("Valid response:", response)
except ValueError as e:
    print("Invalid response:", e)
    # Retry with a more constrained prompt or handle gracefully
```

## Advanced Topics

- **Chaining Calls**: Use one completion’s output as the input prompt for another schema, allowing you to build complex workflows.
- **Custom Validation**: Extend Pydantic models with custom validators to enforce business logic (e.g., rating must be between 0 and 10).
- **Custom Prompts and Context**: Fine-tune your prompts, add system messages, or format instructions to get the best possible structured responses.

## Additional Resources

- [ai-pydantic Documentation](https://ai.pydantic.dev/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [OpenAI API Reference](https://platform.openai.com/docs/introduction)

---

With `ai-pydantic`, you can bring structure, reliability, and trust to your AI assistant’s outputs, ensuring that each response matches your application’s needs.

Below is a Markdown guide summarizing the `weather-agent` example from [ai-pydantic’s official examples](https://ai.pydantic.dev/examples/weather-agent/). This example demonstrates how you can build a structured AI assistant that interprets user queries about weather and returns a consistent, validated data structure.

---

# Weather Agent Example

## Overview

The `weather-agent` example showcases how to use `ai-pydantic` to create an AI assistant that can interpret user input, query a weather API, and produce structured responses. The example uses a Pydantic model to define the shape of the responses (including the weather conditions, temperature, and more) and ensures that the AI output adheres strictly to this structure.

By leveraging `ai-pydantic`, you can create a reliable weather agent that:

- Interprets natural language queries about weather.
- Queries a backend weather API or mock service.
- Returns a validated response with all required fields, ensuring predictable outputs for downstream usage.

## Key Concepts

- **Pydantic Models for Weather Data**: You define a schema for expected weather responses, including fields like `location`, `temperature`, `conditions`, etc.
- **AI Integration**: The assistant uses `ai-pydantic` completions or chat completions to interpret user queries and request data.
- **Validation & Reliability**: The response must comply with the defined schema. If the AI’s response is incomplete or ill-formed, a validation error occurs, allowing you to handle or retry.

## Example Schema Definition

A Pydantic model might look like this (simplified):

```python
from pydantic import BaseModel
from typing import Optional

class WeatherResponse(BaseModel):
    location: str
    temperature_celsius: float
    conditions: str
    humidity: Optional[float] = None
    wind_speed: Optional[float] = None
```

This model sets the expectation that any output from the assistant will have a `location`, `temperature_celsius`, and `conditions`. Optional fields like `humidity` and `wind_speed` add flexibility.

## Example Prompting

In the `weather-agent` example, you would create a prompt that guides the AI model to produce only JSON responses conforming to `WeatherResponse`. For instance:

```python
from ai_pydantic import Completion

completion = Completion[WeatherResponse](
    openai_api_key="YOUR_OPENAI_API_KEY",
    prompt_template="""
    Provide the current weather conditions for Paris, France. 
    Respond only in JSON with the fields: location, temperature_celsius, conditions, humidity, and wind_speed.
    """
)
```

When you run `completion()`, `ai-pydantic` validates that the response from the model matches `WeatherResponse`. If it doesn’t, an error is raised.

## Integrating a Weather API

In the provided example, the assistant might:

1. Parse the user’s query: “What’s the weather like in Paris?”
2. Query a real weather API or use a mock function to retrieve data.
3. Format the retrieved data into the defined Pydantic schema.
4. Return the validated JSON back to the user, ensuring consistent formatting and reliable field presence.

For instance, after fetching weather data:

```python
data = {
    "location": "Paris, France",
    "temperature_celsius": 22.5,
    "conditions": "Partly cloudy",
    "humidity": 65.0,
    "wind_speed": 10.0
}
weather = WeatherResponse(**data)
print(weather)
```

This integrates seamlessly with `ai-pydantic`, which can use the model both as a schema for LLM responses and a validation layer for API data.

## Handling Errors & Edge Cases

If the model returns something that doesn’t match the schema (for example, missing `location`), `ai-pydantic` will throw a validation error. You can catch this and react accordingly:

```python
try:
    response = completion()
    print("Valid response:", response)
except ValueError as e:
    print("Invalid response:", e)
    # Possibly retry with more explicit instructions or fall back to a default response.
```

## Advanced Integration

- **User Queries**: Extend the prompt to dynamically interpret user queries. E.g., if the user asks “What’s the humidity in Berlin?”, the assistant could parse the city and query an API on the fly.
- **Multiple Data Sources**: Combine weather data with other info (like location suggestions) by creating larger composite Pydantic models.
- **Logging & Monitoring**: Since responses are strictly typed, logging and monitoring are easier. You can track how often fields are missing or incorrect.

## Additional Resources

- [Full Weather Agent Example on ai-pydantic.dev](https://ai.pydantic.dev/examples/weather-agent/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [ai-pydantic Documentation](https://ai.pydantic.dev/)
- [OpenAI API Reference](https://platform.openai.com/docs/introduction)

---

By following the `weather-agent` example, you can build a robust, predictable AI-driven weather assistant that strictly adheres to defined data models, ensuring consistent and reliable integrations with frontends, APIs, or other systems.
